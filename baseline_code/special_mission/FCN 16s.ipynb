{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#하이퍼파라미터-세팅-및-seed-고정\" data-toc-modified-id=\"하이퍼파라미터-세팅-및-seed-고정-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>하이퍼파라미터 세팅 및 seed 고정</a></span></li><li><span><a href=\"#학습-데이터-EDA\" data-toc-modified-id=\"학습-데이터-EDA-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>학습 데이터 EDA</a></span></li><li><span><a href=\"#데이터-전처리-함수-정의-(Dataset)\" data-toc-modified-id=\"데이터-전처리-함수-정의-(Dataset)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>데이터 전처리 함수 정의 (Dataset)</a></span></li><li><span><a href=\"#Dataset-정의-및-DataLoader-할당\" data-toc-modified-id=\"Dataset-정의-및-DataLoader-할당-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Dataset 정의 및 DataLoader 할당</a></span><ul class=\"toc-item\"><li><span><a href=\"#데이터-샘플-시각화-(Show-example-image-and-mask)\" data-toc-modified-id=\"데이터-샘플-시각화-(Show-example-image-and-mask)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>데이터 샘플 시각화 (Show example image and mask)</a></span></li></ul></li><li><span><a href=\"#baseline-model\" data-toc-modified-id=\"baseline-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>baseline model</a></span><ul class=\"toc-item\"><li><span><a href=\"#[TODO]-코드-구현-FCN-16s-\" data-toc-modified-id=\"[TODO]-코드-구현-FCN-16s--5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span><font color=\"red\">[TODO] 코드 구현 FCN-16s </font></a></span></li></ul></li><li><span><a href=\"#train,-validation,-test-함수-정의\" data-toc-modified-id=\"train,-validation,-test-함수-정의-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>train, validation, test 함수 정의</a></span></li><li><span><a href=\"#모델-저장-함수-정의\" data-toc-modified-id=\"모델-저장-함수-정의-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>모델 저장 함수 정의</a></span></li><li><span><a href=\"#모델-생성-및-Loss-function,-Optimizer-정의\" data-toc-modified-id=\"모델-생성-및-Loss-function,-Optimizer-정의-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>모델 생성 및 Loss function, Optimizer 정의</a></span></li><li><span><a href=\"#저장된-model-불러오기-(학습된-이후)\" data-toc-modified-id=\"저장된-model-불러오기-(학습된-이후)-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>저장된 model 불러오기 (학습된 이후)</a></span><ul class=\"toc-item\"><li><span><a href=\"#plot_examples()-시각화-함수-정의\" data-toc-modified-id=\"plot_examples()-시각화-함수-정의-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span><code>plot_examples()</code> 시각화 함수 정의</a></span><ul class=\"toc-item\"><li><span><a href=\"#train-set-시각화\" data-toc-modified-id=\"train-set-시각화-9.1.1\"><span class=\"toc-item-num\">9.1.1&nbsp;&nbsp;</span>train set 시각화</a></span></li><li><span><a href=\"#validation-set-시각화\" data-toc-modified-id=\"validation-set-시각화-9.1.2\"><span class=\"toc-item-num\">9.1.2&nbsp;&nbsp;</span>validation set 시각화</a></span></li><li><span><a href=\"#test-set-시각화\" data-toc-modified-id=\"test-set-시각화-9.1.3\"><span class=\"toc-item-num\">9.1.3&nbsp;&nbsp;</span>test set 시각화</a></span></li></ul></li></ul></li><li><span><a href=\"#submission을-위한-test-함수-정의\" data-toc-modified-id=\"submission을-위한-test-함수-정의-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>submission을 위한 test 함수 정의</a></span></li><li><span><a href=\"#submission.csv-생성\" data-toc-modified-id=\"submission.csv-생성-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>submission.csv 생성</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T11:32:16.881249Z",
     "start_time": "2021-10-02T11:32:14.072277Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.8.1\n",
      "GPU 사용 가능 여부: True\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import label_accuracy_score, add_hist\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from matplotlib.patches import Patch\n",
    "import webcolors\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "# GPU 사용 가능 여부에 따라 device 정보 저장\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 세팅 및 seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T11:32:20.523747Z",
     "start_time": "2021-10-02T11:32:20.509747Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8   # Mini-batch size\n",
    "num_epochs = 20\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T11:32:21.562249Z",
     "start_time": "2021-10-02T11:32:21.546749Z"
    }
   },
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 21\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T11:32:30.815749Z",
     "start_time": "2021-10-02T11:32:26.570747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of super categories: 10\n",
      "Number of categories: 10\n",
      "Number of annotations: 26240\n",
      "Number of images: 3272\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "dataset_path  = '../input/data'\n",
    "anns_file_path = dataset_path + '/' + 'train_all.json'\n",
    "\n",
    "# Read annotations\n",
    "with open(anns_file_path, 'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "\n",
    "categories = dataset['categories']\n",
    "anns = dataset['annotations']\n",
    "imgs = dataset['images']\n",
    "nr_cats = len(categories)\n",
    "nr_annotations = len(anns)\n",
    "nr_images = len(imgs)\n",
    "\n",
    "# Load categories and super categories\n",
    "cat_names = []\n",
    "super_cat_names = []\n",
    "super_cat_ids = {}\n",
    "super_cat_last_name = ''\n",
    "nr_super_cats = 0\n",
    "for cat_it in categories:\n",
    "    cat_names.append(cat_it['name'])\n",
    "    super_cat_name = cat_it['supercategory']\n",
    "    # Adding new supercat\n",
    "    if super_cat_name != super_cat_last_name:\n",
    "        super_cat_names.append(super_cat_name)\n",
    "        super_cat_ids[super_cat_name] = nr_super_cats\n",
    "        super_cat_last_name = super_cat_name\n",
    "        nr_super_cats += 1\n",
    "\n",
    "print('Number of super categories:', nr_super_cats)\n",
    "print('Number of categories:', nr_cats)\n",
    "print('Number of annotations:', nr_annotations)\n",
    "print('Number of images:', nr_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T11:32:32.396774Z",
     "start_time": "2021-10-02T11:32:32.166273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count annotations\n",
    "cat_histogram = np.zeros(nr_cats,dtype=int)\n",
    "for ann in anns:\n",
    "    cat_histogram[ann['category_id']-1] += 1\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'Categories': cat_names, 'Number of annotations': cat_histogram})\n",
    "df = df.sort_values('Number of annotations', 0, False)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.title(\"category distribution of train_all set \")\n",
    "plot_1 = sns.barplot(x=\"Number of annotations\", y=\"Categories\", data=df, label=\"Total\", color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T11:32:33.016776Z",
     "start_time": "2021-10-02T11:32:33.002748Z"
    }
   },
   "outputs": [],
   "source": [
    "# category labeling \n",
    "sorted_temp_df = df.sort_index()\n",
    "\n",
    "# background = 0 에 해당되는 label 추가 후 기존들을 모두 label + 1 로 설정\n",
    "sorted_df = pd.DataFrame([\"Backgroud\"], columns = [\"Categories\"])\n",
    "sorted_df = sorted_df.append(sorted_temp_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T11:32:33.605748Z",
     "start_time": "2021-10-02T11:32:33.581749Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Number of annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backgroud</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>General trash</td>\n",
       "      <td>2782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paper</td>\n",
       "      <td>9311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paper pack</td>\n",
       "      <td>659.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metal</td>\n",
       "      <td>562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Glass</td>\n",
       "      <td>610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Plastic</td>\n",
       "      <td>3090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Styrofoam</td>\n",
       "      <td>1343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Plastic bag</td>\n",
       "      <td>7643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Battery</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Clothing</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Categories  Number of annotations\n",
       "0       Backgroud                    NaN\n",
       "1   General trash                 2782.0\n",
       "2           Paper                 9311.0\n",
       "3      Paper pack                  659.0\n",
       "4           Metal                  562.0\n",
       "5           Glass                  610.0\n",
       "6         Plastic                 3090.0\n",
       "7       Styrofoam                 1343.0\n",
       "8     Plastic bag                 7643.0\n",
       "9         Battery                   63.0\n",
       "10       Clothing                  177.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class (Categories) 에 따른 index 확인 (0~10 : 총 11개)\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 함수 정의 (Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T11:32:35.434772Z",
     "start_time": "2021-10-02T11:32:35.411772Z"
    }
   },
   "outputs": [],
   "source": [
    "category_names = list(sorted_df.Categories)\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # General trash = 1, ... , Cigarette = 10\n",
    "            anns = sorted(anns, key=lambda idx : len(idx['segmentation'][0]), reverse=False)\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks[self.coco.annToMask(anns[i]) == 1] = pixel_value\n",
    "            masks = masks.astype(np.int8)\n",
    "                        \n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            return images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            return images, image_infos\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 정의 및 DataLoader 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T11:32:51.957773Z",
     "start_time": "2021-10-02T11:32:47.281747Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.68s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.78s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# train.json / validation.json / test.json 디렉토리 설정\n",
    "train_path = dataset_path + '/train.json'\n",
    "val_path = dataset_path + '/val.json'\n",
    "test_path = dataset_path + '/test.json'\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "train_transform = A.Compose([\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "                          ToTensorV2()\n",
    "                          ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                           ToTensorV2()\n",
    "                           ])\n",
    "\n",
    "# create own Dataset 1 (skip)\n",
    "# validation set을 직접 나누고 싶은 경우\n",
    "# random_split 사용하여 data set을 8:2 로 분할\n",
    "# train_size = int(0.8*len(dataset))\n",
    "# val_size = int(len(dataset)-train_size)\n",
    "# dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=transform)\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# create own Dataset 2\n",
    "# train dataset\n",
    "train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n",
    "\n",
    "# validation dataset\n",
    "val_dataset = CustomDataLoader(data_dir=val_path, mode='val', transform=val_transform)\n",
    "\n",
    "# test dataset\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=4,\n",
    "                                         collate_fn=collate_fn)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 샘플 시각화 (Show example image and mask)\n",
    "\n",
    "- `train_loader` \n",
    "- `val_loader` \n",
    "- `test_loader` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:27:40.843195Z",
     "start_time": "2021-09-08T08:27:40.829194Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_colormap = pd.read_csv(\"class_dict.csv\")\n",
    "class_colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:27:40.858518Z",
     "start_time": "2021-09-08T08:27:40.845696Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_trash_label_colormap():\n",
    "    \"\"\"Creates a label colormap used in Trash segmentation.\n",
    "    Returns:\n",
    "        A colormap for visualizing segmentation results.\n",
    "    \"\"\"\n",
    "    colormap = np.zeros((11, 3), dtype=np.uint8)\n",
    "    for inex, (_, r, g, b) in enumerate(class_colormap.values):\n",
    "        colormap[inex] = [r, g, b]\n",
    "    \n",
    "    return colormap\n",
    "\n",
    "def label_to_color_image(label):\n",
    "    \"\"\"Adds color defined by the dataset colormap to the label.\n",
    "\n",
    "    Args:\n",
    "        label: A 2D array with integer type, storing the segmentation label.\n",
    "\n",
    "    Returns:\n",
    "        result: A 2D array with floating type. The element of the array\n",
    "                is the color indexed by the corresponding element in the input label\n",
    "                to the trash color map.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If label is not of rank 2 or its value is larger than color\n",
    "              map maximum entry.\n",
    "    \"\"\"\n",
    "    if label.ndim != 2:\n",
    "        raise ValueError('Expect 2-D input label')\n",
    "\n",
    "    colormap = create_trash_label_colormap()\n",
    "\n",
    "    if np.max(label) >= len(colormap):\n",
    "        raise ValueError('label value too large.')\n",
    "\n",
    "    return colormap[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T12:45:57.318054Z",
     "start_time": "2021-09-05T12:45:56.793055Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_loader의 output 결과(image 및 mask) 확인\n",
    "for imgs, masks, image_infos in train_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    temp_masks = masks\n",
    "    break\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 12))\n",
    "\n",
    "print('image shape:', list(temp_images[0].shape))\n",
    "print('mask shape: ', list(temp_masks[0].shape))\n",
    "print('Unique values, category of transformed mask : \\n', [{int(i),category_names[int(i)]} for i in list(np.unique(temp_masks[0]))])\n",
    "\n",
    "ax1.imshow(temp_images[0].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "ax2.imshow(temp_masks[0])\n",
    "ax2.grid(False)\n",
    "ax2.set_title(\"masks : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T12:45:57.953556Z",
     "start_time": "2021-09-05T12:45:57.319554Z"
    }
   },
   "outputs": [],
   "source": [
    "# val_loader의 output 결과(image 및 mask) 확인\n",
    "for imgs, masks, image_infos in val_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    temp_masks = masks\n",
    "    \n",
    "    break\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 12))\n",
    "\n",
    "print('image shape:', list(temp_images[0].shape))\n",
    "print('mask shape: ', list(temp_masks[0].shape))\n",
    "\n",
    "print('Unique values, category of transformed mask : \\n', [{int(i),category_names[int(i)]} for i in list(np.unique(temp_masks[0]))])\n",
    "\n",
    "ax1.imshow(temp_images[0].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "ax2.imshow(temp_masks[0])\n",
    "ax2.grid(False)\n",
    "ax2.set_title(\"masks : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T12:45:57.955054Z",
     "start_time": "2021-09-05T12:45:57.955054Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_loader의 output 결과(image) 확인\n",
    "for imgs, image_infos in test_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    \n",
    "    break\n",
    "\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "\n",
    "print('image shape:', list(temp_images[0].shape))\n",
    "\n",
    "ax1.imshow(temp_images[0].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline model\n",
    "\n",
    "### <font color='red'>[TODO] 코드 구현 FCN-16s </font>\n",
    "\n",
    "![FCN16s.png](http://drive.google.com/uc?export=view&id=1Td6ZLqY3A5Mwx9vwLJAyJytNW1ILhZjn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T11:18:31.545779Z",
     "start_time": "2021-10-02T11:18:29.852273Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 참고 코드 \n",
    "# https://github.com/wkentaro/pytorch-fcn/\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class FCN16s(nn.Module):\n",
    "    def __init__(self, num_classes=21):\n",
    "        super(FCN16s, self).__init__()\n",
    "        self.relu    = nn.ReLU(inplace=True)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        [TODO]\n",
    "\n",
    "        ''' \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        [TODO]\n",
    "\n",
    "        '''      \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:27:58.364064Z",
     "start_time": "2021-09-08T08:27:55.793065Z"
    }
   },
   "outputs": [],
   "source": [
    "# 구현된 model에 임의의 input을 넣어 output이 잘 나오는지 test\n",
    "model = FCN16s(num_classes=11)\n",
    "x = torch.randn([1, 3, 512, 512])\n",
    "print(\"input shape : \", x.shape)\n",
    "out = model(x).to(device)\n",
    "print(\"output shape : \", out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, validation, test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:27:59.368955Z",
     "start_time": "2021-09-08T08:27:59.351957Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, model, data_loader, val_loader, criterion, optimizer, saved_dir, val_every, device):\n",
    "    print(f'Start training..')\n",
    "    n_class = 11\n",
    "    best_loss = 9999999\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        hist = np.zeros((n_class, n_class))\n",
    "        for step, (images, masks, _) in enumerate(data_loader):\n",
    "            images = torch.stack(images)       \n",
    "            masks = torch.stack(masks).long() \n",
    "            \n",
    "            # gpu 연산을 위해 device 할당\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            # device 할당\n",
    "            model = model.to(device)\n",
    "            \n",
    "            # inference\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # loss 계산 (cross entropy loss)\n",
    "            loss = criterion(outputs, masks)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            outputs = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
    "            masks = masks.detach().cpu().numpy()\n",
    "            \n",
    "            hist = add_hist(hist, masks, outputs, n_class=n_class)\n",
    "            acc, acc_cls, mIoU, fwavacc, IoU = label_accuracy_score(hist)\n",
    "            \n",
    "            # step 주기에 따른 loss 출력\n",
    "            if (step + 1) % 25 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{step+1}/{len(train_loader)}], \\\n",
    "                        Loss: {round(loss.item(),4)}, mIoU: {round(mIoU,4)}')\n",
    "             \n",
    "        # validation 주기에 따른 loss 출력 및 best model 저장\n",
    "        if (epoch + 1) % val_every == 0:\n",
    "            avrg_loss = validation(epoch + 1, model, val_loader, criterion, device)\n",
    "            if avrg_loss < best_loss:\n",
    "                print(f\"Best performance at epoch: {epoch + 1}\")\n",
    "                print(f\"Save model in {saved_dir}\")\n",
    "                best_loss = avrg_loss\n",
    "                save_model(model, saved_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:27:59.631310Z",
     "start_time": "2021-09-08T08:27:59.620809Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(epoch, model, data_loader, criterion, device):\n",
    "    print(f'Start validation #{epoch}')\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_class = 11\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        \n",
    "        hist = np.zeros((n_class, n_class))\n",
    "        for step, (images, masks, _) in enumerate(data_loader):\n",
    "            \n",
    "            images = torch.stack(images)       \n",
    "            masks = torch.stack(masks).long()  \n",
    "\n",
    "            images, masks = images.to(device), masks.to(device)            \n",
    "            \n",
    "            # device 할당\n",
    "            model = model.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss\n",
    "            cnt += 1\n",
    "            \n",
    "            outputs = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
    "            masks = masks.detach().cpu().numpy()\n",
    "            \n",
    "            hist = add_hist(hist, masks, outputs, n_class=n_class)\n",
    "        \n",
    "        acc, acc_cls, mIoU, fwavacc, IoU = label_accuracy_score(hist)\n",
    "        IoU_by_class = [{classes : round(IoU,4)} for IoU, classes in zip(IoU , sorted_df['Categories'])]\n",
    "        \n",
    "        avrg_loss = total_loss / cnt\n",
    "        print(f'Validation #{epoch}  Average Loss: {round(avrg_loss.item(), 4)}, Accuracy : {round(acc, 4)}, \\\n",
    "                mIoU: {round(mIoU, 4)}')\n",
    "        print(f'IoU by class : {IoU_by_class}')\n",
    "        \n",
    "    return avrg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:28:04.567837Z",
     "start_time": "2021-09-08T08:28:04.557308Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 저장 함수 정의\n",
    "val_every = 1\n",
    "\n",
    "saved_dir = './saved'\n",
    "if not os.path.isdir(saved_dir):                                                           \n",
    "    os.mkdir(saved_dir)\n",
    "\n",
    "def save_model(model, saved_dir, file_name='fcn16s_best_model.pt'):\n",
    "    check_point = {'net': model.state_dict()}\n",
    "    output_path = os.path.join(saved_dir, file_name)\n",
    "    torch.save(model, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성 및 Loss function, Optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:28:06.030571Z",
     "start_time": "2021-09-08T08:28:06.026101Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss function 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer 정의\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T15:08:09.780016Z",
     "start_time": "2021-09-05T12:46:15.172074Z"
    }
   },
   "outputs": [],
   "source": [
    "train(num_epochs, model, train_loader, val_loader, criterion, optimizer, saved_dir, val_every, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장된 model 불러오기 (학습된 이후) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:28:09.752484Z",
     "start_time": "2021-09-08T08:28:08.250186Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# best model 저장된 경로\n",
    "model_path = './saved/fcn16s_best_model.pt'\n",
    "\n",
    "# best model 불러오기\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "state_dict = checkpoint.state_dict()\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model = model.to(device)\n",
    "# 추론을 실행하기 전에는 반드시 설정 (batch normalization, dropout 를 평가 모드로 설정)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `plot_examples()` 시각화 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:45:31.134600Z",
     "start_time": "2021-09-08T08:45:31.111255Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_examples(mode=\"train\", batch_id=0, num_examples=batch_size, dataloaer=train_loader):\n",
    "    \"\"\"Visualization of images and masks according to batch size\n",
    "    Args:\n",
    "        mode: train/val/test (str)\n",
    "        batch_id : 0 (int) \n",
    "        num_examples : 1 ~ batch_size (e.g. 8) (int)\n",
    "        dataloaer : data_loader (dataloader) \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # variable for legend\n",
    "    category_and_rgb = [[category, (r,g,b)] for idx, (category, r, g, b) in enumerate(class_colormap.values)]\n",
    "    legend_elements = [Patch(facecolor=webcolors.rgb_to_hex(rgb), \n",
    "                             edgecolor=webcolors.rgb_to_hex(rgb), \n",
    "                             label=category) for category, rgb in category_and_rgb]\n",
    "    \n",
    "    # test / validation set에 대한 시각화\n",
    "    if (mode in ('train', 'val')):\n",
    "        with torch.no_grad():\n",
    "            for index, (imgs, masks, image_infos) in enumerate(dataloaer):\n",
    "                if index == batch_id:\n",
    "                    image_infos = image_infos\n",
    "                    temp_images = imgs\n",
    "                    temp_masks = masks\n",
    "\n",
    "                    model.eval()\n",
    "                    # inference\n",
    "                    outs = model(torch.stack(temp_images).to(device))\n",
    "                    oms = torch.argmax(outs, dim=1).detach().cpu().numpy()\n",
    "\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "    \n",
    "        fig, ax = plt.subplots(nrows=num_examples, ncols=3, figsize=(12, 4*num_examples), constrained_layout=True)\n",
    "        fig.tight_layout()\n",
    "        for row_num in range(num_examples):\n",
    "            # Original Image\n",
    "            ax[row_num][0].imshow(temp_images[row_num].permute([1,2,0]))\n",
    "            ax[row_num][0].set_title(f\"Orignal Image : {image_infos[row_num]['file_name']}\")\n",
    "            # Groud Truth\n",
    "            ax[row_num][1].imshow(label_to_color_image(masks[row_num].detach().cpu().numpy()))\n",
    "            ax[row_num][1].set_title(f\"Groud Truth : {image_infos[row_num]['file_name']}\")\n",
    "            # Pred Mask\n",
    "            ax[row_num][2].imshow(label_to_color_image(oms[row_num]))\n",
    "            ax[row_num][2].set_title(f\"Pred Mask : {image_infos[row_num]['file_name']}\")\n",
    "            ax[row_num][2].legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "        plt.show()\n",
    "    \n",
    "    # test set에 대한 시각화\n",
    "    else :\n",
    "        with torch.no_grad():\n",
    "            for index, (imgs, image_infos) in enumerate(dataloaer):\n",
    "                if index == batch_id:\n",
    "                    image_infos = image_infos\n",
    "                    temp_images = imgs\n",
    "\n",
    "                    model.eval()\n",
    "                    \n",
    "                    # inference\n",
    "                    outs = model(torch.stack(temp_images).to(device))\n",
    "                    oms = torch.argmax(outs, dim=1).detach().cpu().numpy()\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "    \n",
    "        fig, ax = plt.subplots(nrows=num_examples, ncols=2, figsize=(10, 4*num_examples), constrained_layout=True)\n",
    "\n",
    "        for row_num in range(num_examples):\n",
    "            # Original Image\n",
    "            ax[row_num][0].imshow(temp_images[row_num].permute([1,2,0]))\n",
    "            ax[row_num][0].set_title(f\"Orignal Image : {image_infos[row_num]['file_name']}\")\n",
    "            # Pred Mask\n",
    "            ax[row_num][1].imshow(label_to_color_image(oms[row_num]))\n",
    "            ax[row_num][1].set_title(f\"Pred Mask : {image_infos[row_num]['file_name']}\")\n",
    "            ax[row_num][1].legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "            \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train set 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:45:36.134829Z",
     "start_time": "2021-09-08T08:45:32.303801Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_examples(mode=\"train\", batch_id=7, num_examples=4, dataloaer=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validation set 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:44:20.274388Z",
     "start_time": "2021-09-08T08:44:17.269389Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_examples(mode=\"val\", batch_id=0, num_examples=4, dataloaer=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test set 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T09:20:24.256393Z",
     "start_time": "2021-09-08T09:20:18.633414Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_examples(mode=\"test\", batch_id=0, num_examples=2, dataloaer=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission을 위한 test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:28:21.389218Z",
     "start_time": "2021-09-08T08:28:21.368058Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, data_loader, device):\n",
    "    size = 256\n",
    "    transform = A.Compose([A.Resize(size, size)])\n",
    "    print('Start prediction.')\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    file_name_list = []\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, image_infos) in enumerate(tqdm(test_loader)):\n",
    "            \n",
    "            # inference (512 x 512)\n",
    "            outs = model(torch.stack(imgs).to(device))\n",
    "            oms = torch.argmax(outs, dim=1).detach().cpu().numpy()\n",
    "            \n",
    "            # resize (256 x 256)\n",
    "            temp_mask = []\n",
    "            for img, mask in zip(np.stack(imgs), oms):\n",
    "                transformed = transform(image=img, mask=mask)\n",
    "                mask = transformed['mask']\n",
    "                temp_mask.append(mask)\n",
    "                \n",
    "            oms = np.array(temp_mask)\n",
    "            \n",
    "            oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "            preds_array = np.vstack((preds_array, oms))\n",
    "            \n",
    "            file_name_list.append([i['file_name'] for i in image_infos])\n",
    "    print(\"End prediction.\")\n",
    "    file_names = [y for x in file_name_list for y in x]\n",
    "    \n",
    "    return file_names, preds_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission.csv 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:31:12.612795Z",
     "start_time": "2021-09-08T08:28:21.951795Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = test(model, test_loader, device)\n",
    "\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "submission.to_csv(\"./submission/fcn16s_best_model.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "394.25px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
